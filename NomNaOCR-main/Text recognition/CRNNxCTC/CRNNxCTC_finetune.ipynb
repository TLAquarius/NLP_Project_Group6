{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJ3aMFtIC80i",
    "outputId": "1c60b0f5-28c9-41d0-c9c8-32ab29f3eefb"
   },
   "outputs": [],
   "source": [
    "# https://theailearner.com/2019/05/29/creating-a-crnn-model-to-recognize-text-in-an-image-part-2\n",
    "# https://keras.io/examples/vision/handwriting_recognition\n",
    "# https://github.com/pbcquoc/crnn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append('..')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "APPROACH_NAME = 'CRNNxCTC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL95XLRnDLr0"
   },
   "source": [
    "# Check GPU working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvS8yaEuzsrn",
    "outputId": "5cde58c9-bea0-42da-efb2-d670783148d6"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0': raise SystemError('GPU device not found')\n",
    "print('Found GPU at:', device_name)\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59I4WL9KlLEp"
   },
   "source": [
    "# Data input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m66Z8AzXMwwZ"
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = r'../../Datasets/Patches'\n",
    "ALL_TRANSCRIPTS_PATH = f'{DATASET_DIR}/All.txt'\n",
    "VALID_TRANSCRIPTS_PATH = f'{DATASET_DIR}/Validate.txt'\n",
    "FONT_PATH = r'../../NomNaTong-Regular.ttf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qStF022-zIYh"
   },
   "source": [
    "## Load and remove records with rare characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEu0aBoPIyut",
    "outputId": "614019f9-e971-40c5-810c-6ad3902adeac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from loader import DataImporter\n",
    "dataset = DataImporter(DATASET_DIR, ALL_TRANSCRIPTS_PATH, min_length=1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKW8zQyt2qS4"
   },
   "source": [
    "## Data constants and input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i32zK6nS4rxy"
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 432, 48\n",
    "PADDING_CHAR = '[PAD]' \n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import DataHandler\n",
    "data_handler = DataHandler(dataset, img_size=(HEIGHT, WIDTH), padding_char=PADDING_CHAR)\n",
    "NUM_VALIDATE = DataImporter(DATASET_DIR, VALID_TRANSCRIPTS_PATH, min_length=1).size\n",
    "VOCAB_SIZE = data_handler.char2num.vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV_IIEBlQkT5"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "RqHrvzeSQey4",
    "outputId": "0f05ca27-a4e4-47a1-94f6-0481bc9e3e51",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from visualizer import visualize_images_labels\n",
    "visualize_images_labels(\n",
    "    dataset.img_paths, \n",
    "    dataset.labels, \n",
    "    figsize = (15, 15),\n",
    "    subplot_size = (2, 8),\n",
    "    font_path = FONT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9bOncNGjfey"
   },
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7QHFWNfkL58"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, GRU\n",
    "from layers import custom_cnn, reshape_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crnn(imagenet_model=None, imagenet_output_layer=None, name='CRNN'):\n",
    "    # CNN layers\n",
    "    if imagenet_model: # Use Imagenet model as CNN layers\n",
    "        image_input = imagenet_model.input\n",
    "        imagenet_model.layers[0]._name = 'image'\n",
    "        x = imagenet_model.get_layer(imagenet_output_layer).output\n",
    "    else: \n",
    "        image_input = Input(shape=(HEIGHT, WIDTH, 3), dtype='float32', name='image')\n",
    "        conv_blocks_config = {\n",
    "            'block1': {'num_conv': 1, 'filters':  64, 'pool_size': (2, 2)}, \n",
    "            'block2': {'num_conv': 1, 'filters': 128, 'pool_size': (2, 2)}, \n",
    "            'block3': {'num_conv': 2, 'filters': 256, 'pool_size': (2, 2)}, \n",
    "            'block4': {'num_conv': 2, 'filters': 512, 'pool_size': (2, 2)}, \n",
    "            \n",
    "            # Last Conv blocks with 2x2 kernel but without padding and pooling layer\n",
    "            'block5': {'num_conv': 2, 'filters': 512, 'pool_size': None}, \n",
    "        }\n",
    "        x = custom_cnn(conv_blocks_config, image_input)\n",
    "        \n",
    "    # Reshape accordingly before passing output to RNN\n",
    "    feature_maps = reshape_features(x, dim_to_keep=1, name='rnn_input')\n",
    "    \n",
    "    # RNN layers\n",
    "    bigru1 = Bidirectional(GRU(256, return_sequences=True), name='bigru1')(feature_maps)\n",
    "    bigru2 = Bidirectional(GRU(256, return_sequences=True), name='bigru2')(bigru1)\n",
    "    \n",
    "    # Output layer\n",
    "    y_pred = Dense(\n",
    "        units = VOCAB_SIZE + 1, # + 1 blank character for CTC loss\n",
    "        activation = 'softmax', \n",
    "        name = 'rnn_output'\n",
    "    )(bigru2)\n",
    "    return Model(inputs=image_input, outputs=y_pred, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_imagenet_model\n",
    "imagenet_model, imagenet_output_layer = None, None\n",
    "# # Pick a model from https://keras.io/api/applications\n",
    "# imagenet_model = get_imagenet_model('VGG16', (HEIGHT, WIDTH, 3))\n",
    "# imagenet_output_layer = 'block5_pool'\n",
    "# imagenet_model.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_crnn(imagenet_model, imagenet_output_layer)\n",
    "model.load_weights(\n",
    "    f'./IHR-NomDB/IHR-NomDB_{APPROACH_NAME}.h5', \n",
    "    skip_mismatch = True,\n",
    "    by_name = True,\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-FFbRGWnzKO"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = list(range(dataset.size - NUM_VALIDATE))\n",
    "valid_idxs = list(range(train_idxs[-1] + 1, dataset.size))\n",
    "print('Number of training samples:', len(train_idxs))\n",
    "print('Number of validate samples:', len(valid_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2022)\n",
    "random.shuffle(train_idxs)\n",
    "\n",
    "# When run on a small RAM machine, you can set use_cache=False to \n",
    "# not run out of memory but it will slow down the training speed\n",
    "train_tf_dataset = data_handler.prepare_tf_dataset(train_idxs, BATCH_SIZE)\n",
    "valid_tf_dataset = data_handler.prepare_tf_dataset(valid_idxs, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    min_delta = 1e-3, # Change that less than 1e-3, will count as no improvement\n",
    "    patience = 5, # Stop if no improvement after 5 epochs\n",
    "    restore_best_weights = True, # Restore weights from the epoch with the best value\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the NomNaOCR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import CTCLoss\n",
    "from metrics import SequenceAccuracy, CharacterAccuracy, LevenshteinDistance\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "\n",
    "# Adadelta tends to benefit from higher initial learning rate values compared to\n",
    "# other optimizers. Here use 1.0 to match the exact form in the original paper\n",
    "LEARNING_RATE = 1.0\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adadelta(LEARNING_RATE), \n",
    "    loss = CTCLoss(), \n",
    "    metrics = [\n",
    "        SequenceAccuracy(use_ctc_decode=True),\n",
    "        CharacterAccuracy(use_ctc_decode=True),\n",
    "        LevenshteinDistance(use_ctc_decode=True, normalize=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_tf_dataset,\n",
    "    validation_data = valid_tf_dataset,\n",
    "    epochs = EPOCHS,\n",
    "    callbacks = [early_stopping_callback],\n",
    "    verbose = 1\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = early_stopping_callback.best_epoch\n",
    "print(f'- Loss on validation\\t: {history[\"val_loss\"][best_epoch]}')\n",
    "print(f'- Sequence accuracy\\t: {history[\"val_seq_acc\"][best_epoch]}')\n",
    "print(f'- Character accuracy\\t: {history[\"val_char_acc\"][best_epoch]}')\n",
    "print(f'- Levenshtein distance\\t: {history[\"val_levenshtein_distance\"][best_epoch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizer import plot_training_results\n",
    "plot_training_results(history, f'finetune_{APPROACH_NAME}.png')\n",
    "model.save_weights(f'finetune_{APPROACH_NAME}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFbz4qpk6nKa"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_model = build_crnn(imagenet_model, imagenet_output_layer)\n",
    "reset_model.load_weights(f'Fine-tuning/finetune_{APPROACH_NAME}.h5')\n",
    "reset_model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_model.compile(\n",
    "    optimizer = Adadelta(LEARNING_RATE), \n",
    "    loss = CTCLoss(), \n",
    "    metrics = [\n",
    "        SequenceAccuracy(use_ctc_decode=True),\n",
    "        CharacterAccuracy(use_ctc_decode=True),\n",
    "        LevenshteinDistance(use_ctc_decode=True, normalize=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, (batch_images, batch_tokens) in enumerate(valid_tf_dataset.take(1)):\n",
    "    idxs_in_batch = valid_idxs[idx * BATCH_SIZE: (idx + 1) * BATCH_SIZE]\n",
    "    labels = data_handler.tokens2texts(batch_tokens)\n",
    "    pred_tokens = reset_model.predict(batch_images)\n",
    "    pred_labels = data_handler.tokens2texts(pred_tokens, use_ctc_decode=True)\n",
    "    \n",
    "    visualize_images_labels(\n",
    "        img_paths = dataset.img_paths[idxs_in_batch], \n",
    "        labels = labels, \n",
    "        pred_labels = pred_labels,\n",
    "        figsize = (11.6, 30),\n",
    "        subplot_size = (4, 8),\n",
    "        legend_loc = (3.8, 4.38),\n",
    "        annotate_loc = (4, 2.75),\n",
    "        font_path = FONT_PATH, \n",
    "    )\n",
    "    print(\n",
    "        f'Batch {idx + 1:02d}:\\n'\n",
    "        f'- True: {dict(enumerate(labels, start=1))}\\n'\n",
    "        f'- Pred: {dict(enumerate(pred_labels, start=1))}\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_path = '../囷𦝄苔惮󰞺𧍋𦬑囊.jpg'\n",
    "random_label = '囷𦝄苔惮󰞺𧍋𦬑囊'\n",
    "random_image = data_handler.process_image(random_path)\n",
    "pred_tokens = reset_model.predict(tf.expand_dims(random_image, axis=0))\n",
    "pred_labels = data_handler.tokens2texts(pred_tokens, use_ctc_decode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images_labels(\n",
    "    img_paths = [random_path], \n",
    "    labels = [random_label], \n",
    "    pred_labels = pred_labels,\n",
    "    figsize = (5, 4),\n",
    "    subplot_size = (1, 1), \n",
    "    font_path = FONT_PATH, \n",
    ")\n",
    "print('Predicted text:', ''.join(pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detail evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluator import Evaluator\n",
    "GT10_TRANSCRIPTS_PATH = f'{DATASET_DIR}/Validate_gt10.txt'\n",
    "LTE10_TRANSCRIPTS_PATH = f'{DATASET_DIR}/Validate_lte10.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt10_evaluator = Evaluator(reset_model, DATASET_DIR, GT10_TRANSCRIPTS_PATH)\n",
    "lte10_evaluator = Evaluator(reset_model, DATASET_DIR, LTE10_TRANSCRIPTS_PATH)\n",
    "df = pd.DataFrame([\n",
    "    reset_model.evaluate(valid_tf_dataset, return_dict=True),\n",
    "    gt10_evaluator.evaluate(data_handler, BATCH_SIZE),\n",
    "    lte10_evaluator.evaluate(data_handler, BATCH_SIZE),\n",
    "])\n",
    "df.index = ['Full', 'Length > 10', 'Length ≤ 10']\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CRNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "71a7bf2136a97577d0a8690417094bf6019d7ad150fe8630a15825b0bcf133e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
